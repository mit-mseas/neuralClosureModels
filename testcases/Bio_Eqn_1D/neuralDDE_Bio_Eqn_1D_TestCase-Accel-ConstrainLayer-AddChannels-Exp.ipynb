{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgv1axkGNvut"
   },
   "outputs": [],
   "source": [
    "basedir = '/home/abhinavgupta0110/NeuralODEs_ROM_Closure'\n",
    "\n",
    "import os\n",
    "\n",
    "is_google_colab = False\n",
    "is_use_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq_2LQ9UHud0"
   },
   "source": [
    "### Mount the Google drive if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMm0YJf40nu4"
   },
   "outputs": [],
   "source": [
    "if is_use_GPU:\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "        print('No GPU found!')\n",
    "    else:\n",
    "        print(gpu_info)\n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    %pip install quadpy\n",
    "    \n",
    "os.chdir(os.path.join(basedir, 'neuralClosureModels'))\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp2-6vHzUD"
   },
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MrPJTQD3Xz4"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from src.utilities.DDE_Solver import ddeinttf\n",
    "from src.utilities.helper_classes import * \n",
    "import src.solvers.neuralDDE_with_adjoint_accel_Exp as ndde\n",
    "import src.bio_eqn_case.bio_eqn_1D_modcall_numpy as bio\n",
    "from src.bio_eqn_case.Bio_Eqn_1D_Helper_Classes import * \n",
    "\n",
    "import time\n",
    "import sys\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from shutil import move\n",
    "import pickle\n",
    "\n",
    "print(tf.__version__) \n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6M2Jp_VH7k_"
   },
   "source": [
    "## Define some useful classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAACaFzjH8tF"
   },
   "source": [
    "### Class for user-defined arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuiPlZi330MR"
   },
   "outputs": [],
   "source": [
    "class bio_eq_nDDE_args(ndde.arguments, bio.bio_eqn_args):\n",
    "\n",
    "    def __init__(self, batch_time = 12, batch_time_skip = 2, batch_size = 5, epochs = 500, learning_rate = 0.05, decay_rate = 0.95, test_freq = 1, plot_freq = 2, \n",
    "                 d_max = 1.1, rnn_nmax = 3, rnn_dt = 0.5, adj_data_size = 2,\n",
    "                 model_dir = 'Bio1D_nDistDDE_testcase_v2/model_dir_test', restart = 0, val_percentage = 0.2,\n",
    "                 T = 365.*2, nt = 365*2, nz = 50, z_max = -100, k_w = 0.067, alpha = 0.025, V_m = 1.5, I_0 = 158.075, \n",
    "                 K_u = 1., Psi = 1.46, Xi = 0.1, R_m = 1.5, Lambda = 0.06, gamma = 0.3, Tau = 0.145, \n",
    "                 Phi = 0.175, Omega = 0.041, T_bio_min = 10., T_bio_max = 30., wp = 0.65, wd = 8.0, \n",
    "                 K_zb = 0.0864, K_z0 = 100.*0.0864, gamma_K = 0.1, T_mld = 365, bio_model_low_complex = 'NPZ', bio_model_high_complex = 'NNPZD', isplot = True,\n",
    "                 ode_alg_name = 'dopri5', nsteps = 1, is_tstart_zero = True): # add more arguments as needed\n",
    "        \n",
    "        if bio_model_low_complex == 'NPZ': state_dim = 3*nz\n",
    "        elif bio_model_low_complex == 'NPZD': state_dim = 4*nz\n",
    "        elif bio_model_low_complex == 'NNPZD': state_dim = 5*nz\n",
    "\n",
    "        ndde.arguments.__init__(self, data_size = nt, batch_time = batch_time, batch_time_skip = batch_time_skip, batch_size = batch_size, epochs = epochs,\n",
    "                           learning_rate = learning_rate, decay_rate = decay_rate, test_freq = test_freq, plot_freq = plot_freq, d_max = d_max, rnn_nmax = rnn_nmax, \n",
    "                           rnn_dt = rnn_dt, state_dim = state_dim, adj_data_size = state_dim, model_dir = model_dir, restart = restart, val_percentage = val_percentage, isplot = isplot, is_tstart_zero = is_tstart_zero)\n",
    "\n",
    "        bio.bio_eqn_args.__init__(self, T = T, nt = nt, nz = nz, z_max = z_max, k_w = k_w, alpha = alpha, V_m = V_m, I_0 = I_0, K_u = K_u, Psi = Psi,\n",
    "                    Xi = Xi, R_m = R_m, Lambda = Lambda, gamma = gamma, Tau = Tau, Phi = Phi, Omega = Omega, T_bio_min = T_bio_min, T_bio_max = T_bio_max,\n",
    "                                  wp = wp, wd = wd, bio_model = bio_model_low_complex, K_zb = K_zb, K_z0 = K_z0, gamma_K = gamma_K, T_mld = T_mld)\n",
    "        \n",
    "        self.bio_args_for_high_complex = bio.bio_eqn_args(T = T, nt = nt, nz = nz, z_max = z_max, k_w = k_w, alpha = alpha, V_m = V_m, I_0 = I_0, K_u = K_u, Psi = Psi,\n",
    "                    Xi = Xi, R_m = R_m, Lambda = Lambda, gamma = gamma, Tau = Tau, Phi = Phi, Omega = Omega, T_bio_min = T_bio_min, T_bio_max = T_bio_max,\n",
    "                                  wp = wp, wd = wd, bio_model = bio_model_high_complex)\n",
    "        \n",
    "        self.bio_model_low_complex = bio_model_low_complex\n",
    "        self.bio_model_high_complex = bio_model_high_complex\n",
    "        self.ode_alg_name = ode_alg_name\n",
    "        self.nsteps = nsteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bgp85pBOIHjP"
   },
   "source": [
    "### Define the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNNConv1DCell(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, input_shape, filter_size, kernel_size, strides, activation = 'tanh', padding = 'valid', **kwargs):\n",
    "        \n",
    "        self.kernel_size = kernel_size\n",
    "        self.filter_size = filter_size\n",
    "        self.strides = strides\n",
    "        \n",
    "        self.state_size = tf.TensorShape([input_shape[-2], self.filter_size])\n",
    "        self.output_size = tf.TensorShape([np.floor((input_shape[-2] - self.kernel_size)/self.strides).astype(int), self.filter_size])\n",
    "        \n",
    "        self.c_h_inp = tf.keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, strides=1, activation=None, padding='same',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c_h_h = tf.keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, strides=1, activation=None, padding='same',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=False)\n",
    "        \n",
    "        self.c_out_h = tf.keras.layers.Conv1D(filters=filter_size, kernel_size=kernel_size, strides=strides, activation=activation, padding=padding,\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.act = tf.keras.layers.Activation(activation)\n",
    "        \n",
    "        super(SimpleRNNConv1DCell, self).__init__(**kwargs)\n",
    "\n",
    "    def call(self, input_at_t, states_at_t):\n",
    "        states_at_tp1 = self.c_h_inp(input_at_t) + self.c_h_h(states_at_t[0])\n",
    "        states_at_tp1 = self.act(states_at_tp1)\n",
    "        output_at_tp1 = self.c_out_h(states_at_tp1)\n",
    "        return output_at_tp1, [states_at_tp1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioConstrainLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super(BioConstrainLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.gamma = tf.Variable(0.1, trainable=True, constraint = self.constraint)\n",
    "        \n",
    "    def constraint(self, gamma):\n",
    "        \n",
    "        out = tf.where(gamma <= 1., tf.where(gamma >= 0., gamma, 0.), 1.)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def call(self, input):\n",
    "        \n",
    "        N_channel = self.gamma * input\n",
    "        P_channel = - input\n",
    "        Z_channel = (1. - self.gamma) * input\n",
    "        \n",
    "        output = tf.concat([N_channel, P_channel, Z_channel], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddExtraChannel(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super(AddExtraChannel, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def call(self, input, channels_to_add):\n",
    "#         channels_to_add = tf.tile(channels_to_add, [input.shape[0], 1, 1])\n",
    "        output = tf.concat([input, channels_to_add], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzl-0Opj4CWm"
   },
   "outputs": [],
   "source": [
    "class DDEFuncMain(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, args, **kwargs):\n",
    "        super(DDEFuncMain, self).__init__(**kwargs)\n",
    "\n",
    "        self.rnn_layer = tf.keras.layers.RNN(SimpleRNNConv1DCell(input_shape = [args.nz, 3], \n",
    "                                                                 filter_size = 5, kernel_size = 1, strides = 1, \n",
    "                                                                 activation = 'swish'))\n",
    "        \n",
    "        self.depth = AddExtraChannel()\n",
    "        \n",
    "        self.c1 = tf.keras.layers.Conv1D(filters=7, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c2 = tf.keras.layers.Conv1D(filters=9, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c3 = tf.keras.layers.Conv1D(filters=9, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c4 = tf.keras.layers.Conv1D(filters=7, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c5 = tf.keras.layers.Conv1D(filters=5, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c6 = tf.keras.layers.Conv1D(filters=3, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c_out = tf.keras.layers.Conv1D(filters=1, kernel_size=1, strides=1, activation='linear',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.bio = BioConstrainLayer()\n",
    "        \n",
    "        self.flat = tf.keras.layers.Flatten('channels_first')\n",
    "        \n",
    "        self.args = args\n",
    "\n",
    "    @tf.function\n",
    "    def pass_layers(self, y_nn, channels_to_add=None):\n",
    "        \n",
    "        y_nn = self.layers[0](y_nn)\n",
    "        y_nn = self.layers[1](y_nn, channels_to_add)\n",
    "        \n",
    "        for i in range(2, len(self.layers)):\n",
    "            y_nn = self.layers[i](y_nn)\n",
    "            \n",
    "        return y_nn\n",
    "    \n",
    "    def call(self, y_nn, channels_to_add=None):\n",
    "        \n",
    "        y_nn = self.pass_layers(y_nn, channels_to_add)\n",
    "        \n",
    "        return y_nn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscDDEFunc(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, main, rom_model, args, **kwargs):\n",
    "        super(DiscDDEFunc, self).__init__(**kwargs)\n",
    "        \n",
    "        self.main = main\n",
    "        self.rom_model = rom_model\n",
    "        self.args = args\n",
    "        \n",
    "    def process_input(self, y, t ,d, t_start):     \n",
    "        input = []\n",
    "        for i in np.flip(np.arange(d[0])): # d is a list and d[0] contains the number of steps, while d[1] contains the time-step value to skip\n",
    "            input.append(tf.expand_dims(y(t - i*d[1]), axis=0))\n",
    "\n",
    "        input = tf.concat(input, axis=0)\n",
    "        input = tf.transpose(input, perm=[1, 0] + [i for i in range(2, input.shape.rank)])\n",
    "        input = tf.expand_dims(input, axis=-1)\n",
    "        input = tf.reshape(input, [input.shape[0], input.shape[1], tf.floor(self.args.state_dim / self.args.nz), -1])\n",
    "        input = tf.transpose(input, perm=[i for i in range(0, input.shape.rank-2)] + [input.shape.rank-1, input.shape.rank-2])\n",
    "        \n",
    "        z = tf.tile(tf.expand_dims(tf.expand_dims(self.args.z, axis=-1), axis=0), [t_start.shape[0], 1, 1])\n",
    "        I = tf.concat([tf.expand_dims(tf.expand_dims(self.args.I(t + t_start[i]), axis=-1), axis=0) for i in range(t_start.shape[0])], axis=0)\n",
    "        \n",
    "        channels_to_add = tf.concat([z, I], axis=-1)\n",
    "        \n",
    "        return input, channels_to_add\n",
    "\n",
    "    def call_nn_part(self, input, channels_to_add):\n",
    "        dy_dt = self.main(input, channels_to_add)\n",
    "        return dy_dt\n",
    "    \n",
    "    def __call__(self, y, t ,d, t_start = np.array([0.])):\n",
    "        \n",
    "        y_nn, channels_to_add = self.process_input(y, t, d, t_start)\n",
    "\n",
    "        dy_dt = self.call_nn_part(y_nn, channels_to_add) + self.rom_model(y, t, t_start)\n",
    "        \n",
    "        return dy_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55JqC28YIS6c"
   },
   "source": [
    "### Initialize model related parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYlTE72b4PE2"
   },
   "outputs": [],
   "source": [
    "args = bio_eq_nDDE_args(batch_time = 6, batch_time_skip = 2, batch_size = 8, epochs = 200, learning_rate = 0.05, \n",
    "                        decay_rate = 0.97, test_freq = 1, plot_freq = 1, d_max = 5., rnn_nmax = 4+1, rnn_dt = 0.25, \n",
    "                        model_dir = 'Bio1D_nDDE_testcase_v3/model_dir_case_test', restart = 0, val_percentage = 1.,\n",
    "                        T = 30, nt = 300, nz = 20, z_max = -100, k_w = 0.067, alpha = 0.025, V_m = 1.5, I_0 = 158.075, \n",
    "                        K_u = 1., Psi = 1.46, Xi = 0.1, R_m = 1.5, Lambda = 0.06, gamma = 0.3, Tau = 0.145, \n",
    "                        Phi = 0.175, Omega = 0.041, T_bio_min = 10., T_bio_max = 30., wp = 0*0.65, wd = 0*8.0, \n",
    "                        K_zb = 0.0864, K_z0 = 100.*0.0864, gamma_K = 0.1, T_mld = 365, bio_model_low_complex = 'NPZ', \n",
    "                        bio_model_high_complex = 'NNPZD', isplot = True, ode_alg_name = 'dopri5', nsteps = 5, \n",
    "                        is_tstart_zero = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3D0icD8IV9O"
   },
   "source": [
    "### Make a copy of the current script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "204TIzQKHNzQ"
   },
   "outputs": [],
   "source": [
    "testcase_dir = 'neuralClosureModels/testcases/Bio_Eqn_1D'\n",
    "save_dir_obj = save_dir(args = args, basedir = basedir, testcase_dir = testcase_dir, save_user_inputs=False)\n",
    "save_dir_obj(script_name = 'neuralDDE_Bio_Eqn_1D_TestCase-Accel-ConstrainLayer-AddChannels-Exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeBwqst9IqRq"
   },
   "source": [
    "### Run setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(basedir, testcase_dir))\n",
    "\n",
    "%run -i setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_loss:\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.T_bio = tf.expand_dims(tf.expand_dims(args.T_bio, axis=0), axis=0)\n",
    "\n",
    "    def __call__(self, true_y, pred_y):\n",
    "        \n",
    "        true_y = tf.reshape(true_y, [true_y.shape[0], true_y.shape[1], tf.floor(self.args.state_dim / self.args.nz), -1])\n",
    "        true_y = tf.transpose(true_y, perm=[0, 1, 3, 2])\n",
    "        pred_y = tf.reshape(pred_y, [pred_y.shape[0], pred_y.shape[1], tf.floor(self.args.state_dim / self.args.nz), -1])\n",
    "        pred_y = tf.transpose(pred_y, perm=[0, 1, 3, 2])\n",
    "        \n",
    "        loss = tf.sqrt(tf.reduce_sum(tf.math.squared_difference(pred_y, true_y), axis=-1) + 1e-10)\n",
    "        loss = tf.reduce_mean(loss, axis=-1)\n",
    "        loss = tf.reduce_mean(loss, axis=0)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9mHAYKBI1vM"
   },
   "source": [
    "## Main part starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pscaRbpsJE25"
   },
   "source": [
    "### Make objects and define learning-rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnb1m74W8a3l"
   },
   "outputs": [],
   "source": [
    "time_meter = ndde.RunningAverageMeter(0.97)\n",
    "\n",
    "rom_model = bio.bio_eqn(args, K_z_obj)\n",
    "func_main = DDEFuncMain(args)\n",
    "func = DiscDDEFunc(func_main, rom_model, args)\n",
    "adj_func = ndde.adj_eqn(func, args, rom_model.jac_npz)\n",
    "get_batch = ndde.create_batch(true_x_low_complex, x0_low_complex, t, args)\n",
    "loss_obj = custom_loss(args)\n",
    "plot_obj = custom_plot(tf.concat([true_x_low_complex, val_true_x_low_complex], axis=0), tf.concat([x_low_complex, val_x_low_complex], axis=0), \n",
    "                       args.z, tf.concat([t, val_t], axis=0), save_dir_obj.figsave_dir, args)\n",
    "loss_history = ndde.history(args)\n",
    "\n",
    "initial_learning_rate = args.learning_rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=args.niters,\n",
    "    decay_rate=args.decay_rate,\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni3vuuA4JLWc"
   },
   "source": [
    "### Quick test to see how the true coefficients looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhCfEgh9HnJ5"
   },
   "outputs": [],
   "source": [
    "if args.restart == 1: \n",
    "    func.load_weights(tf.train.latest_checkpoint(save_dir_obj.checkpoint_dir))\n",
    "    pred_y = ddeinttf(func, x0_low_complex, tf.concat([t, val_t], axis=0), fargs=([args.rnn_nmax, args.rnn_dt],), alg_name = args.ode_alg_name, nsteps = args.nsteps)\n",
    "    \n",
    "    plot_obj.plot(pred_y, epoch = 0)\n",
    "\n",
    "    loss_history.read()\n",
    "    \n",
    "    initial_learning_rate = 0.02\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=args.niters, decay_rate=0.98, staircase=True)\n",
    "    \n",
    "else:\n",
    "    plot_obj.plot(epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RRmGtVWJRWC"
   },
   "source": [
    "### Training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKLUq67EHpoy"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr_schedule)\n",
    "\n",
    "nDDE_train_obj = ndde.train_nDDE(func = func, adj_func = adj_func, d = [args.rnn_nmax, args.rnn_dt], loss_obj = loss_obj, batch_obj = get_batch,\n",
    "                            optimizer = optimizer, args = args, plot_obj = plot_obj, time_meter = time_meter, checkpoint_dir = save_dir_obj.checkpoint_prefix, \n",
    "                            validation_obj = val_obj, loss_history_obj = loss_history)\n",
    "\n",
    "nDDE_train_obj.train(true_x_low_complex, x0_low_complex, t, val_true_x_low_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "neuralDDE_Bio_Eqn_TestCase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
