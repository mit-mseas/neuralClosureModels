{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgv1axkGNvut"
   },
   "outputs": [],
   "source": [
    "basedir = '/home/abhinavgupta0110/NeuralODEs_ROM_Closure'\n",
    "\n",
    "import os\n",
    "\n",
    "is_google_colab = False\n",
    "is_use_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq_2LQ9UHud0"
   },
   "source": [
    "### Mount the Google drive if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMm0YJf40nu4"
   },
   "outputs": [],
   "source": [
    "if is_use_GPU:\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "        print('No GPU found!')\n",
    "    else:\n",
    "        print(gpu_info)\n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    %pip install quadpy\n",
    "    \n",
    "os.chdir(os.path.join(basedir, 'neuralClosureModels'))\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp2-6vHzUD"
   },
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MrPJTQD3Xz4"
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "\n",
    "from src.utilities.DDE_Solver import ddeinttf \n",
    "from src.utilities.helper_classes import *\n",
    "import src.solvers.neuralDistDDE_with_adjoint_accel_Exp as nddde\n",
    "import src.bio_eqn_case.bio_eqn_1D_modcall_numpy as bio\n",
    "from src.bio_eqn_case.Bio_Eqn_1D_Helper_Classes import * \n",
    "\n",
    "import time\n",
    "import sys\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import scipy.interpolate\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from shutil import move\n",
    "import pickle\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6M2Jp_VH7k_"
   },
   "source": [
    "## Define some useful classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAACaFzjH8tF"
   },
   "source": [
    "### Class for user-defined arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuiPlZi330MR"
   },
   "outputs": [],
   "source": [
    "class bio_eq_nDistDDE_args(nddde.nddde_arguments, bio.bio_eqn_args):\n",
    "\n",
    "    def __init__(self, batch_time = 12, batch_time_skip = 2, batch_size = 5, epochs = 500, learning_rate = 0.05, decay_rate = 0.95, test_freq = 1, plot_freq = 2, \n",
    "                 d_max = 1, nn_d1 = 0., nn_d2 = 0.5, adj_data_size = 2,\n",
    "                 model_dir = 'Bio1D_nDistDDE_testcase_v2/model_dir_test', restart = 0, val_percentage = 0.2,\n",
    "                 T = 365.*2, nt = 365*2, nz = 50, z_max = -100, k_w = 0.067, alpha = 0.025, V_m = 1.5, I_0 = 158.075, \n",
    "                 K_u = 1., Psi = 1.46, Xi = 0.1, R_m = 1.5, Lambda = 0.06, gamma = 0.3, Tau = 0.145, \n",
    "                 Phi = 0.175, Omega = 0.041, T_bio_min = 10., T_bio_max = 30., wp = 0.65, wd = 8.0, \n",
    "                 K_zb = 0.0864, K_z0 = 100.*0.0864, gamma_K = 0.1, T_mld = 365, bio_model_low_complex = 'NPZ', bio_model_high_complex = 'NNPZD', isplot = True,\n",
    "                 ode_alg_name = 'dopri5', nsteps = 1, is_tstart_zero = True): # add more arguments as needed\n",
    "        \n",
    "        if bio_model_low_complex == 'NPZ': state_dim = 3*nz\n",
    "        elif bio_model_low_complex == 'NPZD': state_dim = 4*nz\n",
    "        elif bio_model_low_complex == 'NNPZD': state_dim = 5*nz\n",
    "\n",
    "        nddde.nddde_arguments.__init__(self, data_size = nt, batch_time = batch_time, batch_time_skip = batch_time_skip, batch_size = batch_size, epochs = epochs,\n",
    "                           learning_rate = learning_rate, decay_rate = decay_rate, test_freq = test_freq, plot_freq = plot_freq, d_max = d_max, nn_d1 = nn_d1,\n",
    "                           nn_d2 = nn_d2, state_dim = state_dim, adj_data_size = state_dim, model_dir = model_dir, restart = restart, val_percentage = val_percentage, isplot = isplot, is_tstart_zero = is_tstart_zero)\n",
    "\n",
    "        bio.bio_eqn_args.__init__(self, T = T, nt = nt, nz = nz, z_max = z_max, k_w = k_w, alpha = alpha, V_m = V_m, I_0 = I_0, K_u = K_u, Psi = Psi,\n",
    "                    Xi = Xi, R_m = R_m, Lambda = Lambda, gamma = gamma, Tau = Tau, Phi = Phi, Omega = Omega, T_bio_min = T_bio_min, T_bio_max = T_bio_max,\n",
    "                                  wp = wp, wd = wd, bio_model = bio_model_low_complex, K_zb = K_zb, K_z0 = K_z0, gamma_K = gamma_K, T_mld = T_mld)\n",
    "        \n",
    "        self.bio_args_for_high_complex = bio.bio_eqn_args(T = T, nt = nt, nz = nz, z_max = z_max, k_w = k_w, alpha = alpha, V_m = V_m, I_0 = I_0, K_u = K_u, Psi = Psi,\n",
    "                    Xi = Xi, R_m = R_m, Lambda = Lambda, gamma = gamma, Tau = Tau, Phi = Phi, Omega = Omega, T_bio_min = T_bio_min, T_bio_max = T_bio_max,\n",
    "                                  wp = wp, wd = wd, bio_model = bio_model_high_complex)\n",
    "        \n",
    "        self.bio_model_low_complex = bio_model_low_complex\n",
    "        self.bio_model_high_complex = bio_model_high_complex\n",
    "        self.ode_alg_name = ode_alg_name\n",
    "        self.nsteps = nsteps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bgp85pBOIHjP"
   },
   "source": [
    "### Define the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioConstrainLayer(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super(BioConstrainLayer, self).__init__(**kwargs)\n",
    "        \n",
    "        self.gamma = tf.Variable(0.1, trainable=True, constraint = self.constraint)\n",
    "        \n",
    "    def constraint(self, gamma):\n",
    "        \n",
    "        out = tf.where(gamma <= 1., tf.where(gamma >= 0., gamma, 0.), 1.)\n",
    "        \n",
    "        return out\n",
    "        \n",
    "        \n",
    "    def call(self, input):\n",
    "        \n",
    "        N_channel = self.gamma * input\n",
    "        P_channel = - input\n",
    "        Z_channel = (1. - self.gamma) * input\n",
    "        \n",
    "        output = tf.concat([N_channel, P_channel, Z_channel], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddExtraChannel(tf.keras.layers.Layer):\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        \n",
    "        super(AddExtraChannel, self).__init__(**kwargs)\n",
    "\n",
    "        \n",
    "    def call(self, input, channels_to_add):\n",
    "\n",
    "        output = tf.concat([input, channels_to_add], axis=-1)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzl-0Opj4CWm"
   },
   "outputs": [],
   "source": [
    "class DDEFuncMain(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, args, **kwargs):\n",
    "        super(DDEFuncMain, self).__init__(**kwargs)\n",
    "        \n",
    "        self.depth = AddExtraChannel()\n",
    "        \n",
    "        self.c1 = tf.keras.layers.Conv1D(filters=7, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c2 = tf.keras.layers.Conv1D(filters=9, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c3 = tf.keras.layers.Conv1D(filters=9, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c4 = tf.keras.layers.Conv1D(filters=7, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c5 = tf.keras.layers.Conv1D(filters=5, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c6 = tf.keras.layers.Conv1D(filters=3, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c_out = tf.keras.layers.Conv1D(filters=1, kernel_size=1, strides=1, activation='linear',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "\n",
    "        self.bio = BioConstrainLayer()\n",
    "        \n",
    "        self.flat = tf.keras.layers.Flatten('channels_first')\n",
    "        \n",
    "        self.args = args\n",
    "    \n",
    "    def process_input(self, zy):     \n",
    "        \n",
    "        z = zy[:, :self.args.state_dim]\n",
    "        z = tf.reshape(z, [z.shape[0], tf.floor(self.args.state_dim / self.args.nz), -1])\n",
    "        z = tf.transpose(z, perm=[0, 2, 1])\n",
    "        y = zy[:, self.args.state_dim:]\n",
    "        y = tf.reshape(y, [z.shape[0], -1, self.args.nz])\n",
    "        y = tf.transpose(y, perm=[0, 2, 1])\n",
    "        z_stack_y = tf.concat([z, y], axis=-1)\n",
    "        \n",
    "        return z_stack_y\n",
    "    \n",
    "    @tf.function\n",
    "    def pass_layers(self, z, channels_to_add=None):\n",
    "        \n",
    "        z = self.layers[0](z, channels_to_add)\n",
    "        \n",
    "        for i in range(1, len(self.layers)):\n",
    "            z = self.layers[i](z)\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def call(self, z, channels_to_add=None):\n",
    "        \n",
    "        z = self.process_input(z)\n",
    "        \n",
    "        z = self.pass_layers(z, channels_to_add)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGruWRo3E4Wf"
   },
   "outputs": [],
   "source": [
    "class DDEFuncAux(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, args, **kwargs):\n",
    "        super(DDEFuncAux, self).__init__(**kwargs)\n",
    "        \n",
    "        self.c1 = tf.keras.layers.Conv1D(filters=3, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c2 = tf.keras.layers.Conv1D(filters=5, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c3 = tf.keras.layers.Conv1D(filters=7, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.c4 = tf.keras.layers.Conv1D(filters=5, kernel_size=1, strides=1, activation='swish',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.dc_out = tf.keras.layers.Conv1D(filters=2, kernel_size=1, strides=1, activation='linear',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.flat = tf.keras.layers.Flatten('channels_first')\n",
    "        \n",
    "        self.args = args\n",
    "    \n",
    "    def process_input(self, z):     \n",
    "               \n",
    "        z = tf.reshape(z, [z.shape[0], -1, self.args.nz])\n",
    "        z = tf.transpose(z, perm=[0, 2, 1])\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    @tf.function\n",
    "    def pass_layers(self, z):\n",
    "        \n",
    "        for i in range(len(self.layers)):\n",
    "            z = self.layers[i](z)\n",
    "            \n",
    "        return z\n",
    "    \n",
    "    def call(self, z):\n",
    "        \n",
    "        z = self.process_input(z)\n",
    "        \n",
    "        z = self.pass_layers(z)\n",
    "        \n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JZMekSKE40r"
   },
   "outputs": [],
   "source": [
    "class split_zy:\n",
    "    def __init__(self, zy, args):\n",
    "        self.zy = zy\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self, t):\n",
    "        return self.zy(t)[:, :self.args.state_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2udHo64E6rk"
   },
   "outputs": [],
   "source": [
    "class DistDDEFunc(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, main, aux, rom_model, args, **kwargs):\n",
    "        super(DistDDEFunc, self).__init__(**kwargs)\n",
    "        self.main = main\n",
    "        self.aux = aux\n",
    "        self.rom_model = rom_model\n",
    "        self.args = args\n",
    "        \n",
    "    def process_input(self, y, t ,d, t_start):     \n",
    "        \n",
    "        input = [y(t)]\n",
    "        input.append(y(t - d[0])[:, :self.args.state_dim])\n",
    "        input.append(y(t - d[1])[:, :self.args.state_dim])\n",
    "        \n",
    "        z = tf.tile(tf.expand_dims(tf.expand_dims(self.args.z, axis=-1), axis=0), [t_start.shape[0], 1, 1])\n",
    "        I = tf.concat([tf.expand_dims(tf.expand_dims(self.args.I(t + t_start[i]), axis=-1), axis=0) for i in range(t_start.shape[0])], axis=0)\n",
    "        \n",
    "        channels_to_add = tf.concat([z, I], axis=-1)\n",
    "        \n",
    "        return input, channels_to_add\n",
    "    \n",
    "    def call_nn_part(self, input, channels_to_add):\n",
    "        dz_dt = self.main(input[0], channels_to_add)\n",
    "        gz_t1 = self.aux(input[1])\n",
    "        gz_t2 = self.aux(input[2])\n",
    "        dy_dt = gz_t1 - gz_t2\n",
    "        \n",
    "        return tf.concat([dz_dt, dy_dt], axis=-1)\n",
    "\n",
    "    def __call__(self, y, t ,d, t_start = np.array([0.])):\n",
    "        \n",
    "        get_z = split_zy(y, self.args)       \n",
    "        \n",
    "        input, channels_to_add = self.process_input(y, t ,d, t_start)\n",
    "        dzy_dt = self.call_nn_part(input, channels_to_add)\n",
    "        \n",
    "        rom_output = self.rom_model(get_z, t, t_start)\n",
    "        rom_output = tf.concat([rom_output, tf.zeros([dzy_dt.shape[0], dzy_dt.shape[1] - rom_output.shape[1]])], axis=-1)\n",
    "        \n",
    "        dzy_dt = dzy_dt + rom_output\n",
    "        \n",
    "        return dzy_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55JqC28YIS6c"
   },
   "source": [
    "### Initialize model related parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYlTE72b4PE2"
   },
   "outputs": [],
   "source": [
    "args = bio_eq_nDistDDE_args(batch_time = 6, batch_time_skip = 2, batch_size = 4, epochs = 200, learning_rate = 0.05, \n",
    "                            decay_rate = 0.97, test_freq = 1, plot_freq = 1, d_max = 5., nn_d1 = 0., nn_d2 = 2., \n",
    "                            model_dir = 'Bio1D_nDistDDE_testcase_v3/model_dir_case_test', restart = 0, val_percentage = 1.,\n",
    "                            T = 30, nt = 300, nz = 20, z_max = -100, k_w = 0.067, alpha = 0.025, V_m = 1.5, I_0 = 158.075, \n",
    "                            K_u = 1., Psi = 1.46, Xi = 0.1, R_m = 1.5, Lambda = 0.06, gamma = 0.3, Tau = 0.145, \n",
    "                            Phi = 0.175, Omega = 0.041, T_bio_min = 10., T_bio_max = 30., wp = 0*0.65, wd = 0*8.0, \n",
    "                            K_zb = 0.0864, K_z0 = 100.*0.0864, gamma_K = 0.1, T_mld = 365, bio_model_low_complex = 'NPZ', \n",
    "                            bio_model_high_complex = 'NNPZD', isplot = True, ode_alg_name = 'dopri5', nsteps = 5, \n",
    "                            is_tstart_zero = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3D0icD8IV9O"
   },
   "source": [
    "### Make a copy of the current script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "204TIzQKHNzQ"
   },
   "outputs": [],
   "source": [
    "testcase_dir = 'neuralClosureModels/testcases/Bio_Eqn_1D'\n",
    "save_dir_obj = save_dir(args = args, basedir = basedir, testcase_dir = testcase_dir, save_user_inputs=False)\n",
    "save_dir_obj(script_name = 'neuralDistDDE_Bio_Eqn_1D_TestCase-Accel-ConstrainLayer-AddChannels-Exp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeBwqst9IqRq"
   },
   "source": [
    "### Run setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(os.path.join(basedir, testcase_dir))\n",
    "\n",
    "%run -i setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class custom_loss:\n",
    "    \n",
    "    def __init__(self, args):\n",
    "        self.args = args\n",
    "        self.T_bio = tf.expand_dims(tf.expand_dims(args.T_bio, axis=0), axis=0)\n",
    "\n",
    "    def __call__(self, true_y, pred_y):\n",
    "        \n",
    "        true_y = tf.reshape(true_y, [true_y.shape[0], true_y.shape[1], tf.floor(self.args.state_dim / self.args.nz), -1])\n",
    "        true_y = tf.transpose(true_y, perm=[0, 1, 3, 2])\n",
    "        pred_y = tf.reshape(pred_y, [pred_y.shape[0], pred_y.shape[1], tf.floor(self.args.state_dim / self.args.nz), -1])\n",
    "        pred_y = tf.transpose(pred_y, perm=[0, 1, 3, 2])\n",
    "        \n",
    "        loss = tf.sqrt(tf.reduce_sum(tf.math.squared_difference(pred_y, true_y), axis=-1) + 1e-10)\n",
    "        loss = tf.reduce_mean(loss, axis=-1)\n",
    "        loss = tf.reduce_mean(loss, axis=0)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9mHAYKBI1vM"
   },
   "source": [
    "## Main part starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pscaRbpsJE25"
   },
   "source": [
    "### Make objects and define learning-rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnb1m74W8a3l"
   },
   "outputs": [],
   "source": [
    "time_meter = nddde.RunningAverageMeter(0.97)\n",
    "\n",
    "func_main = DDEFuncMain(args)\n",
    "func_aux = DDEFuncAux(args)\n",
    "rom_model = bio.bio_eqn(args, K_z_obj)\n",
    "func = DistDDEFunc(func_main, func_aux, rom_model, args)\n",
    "adj_func = nddde.nddde_adj_eqn(func, args, rom_model.jac_npz)\n",
    "get_batch = nddde.create_batch(true_x_low_complex, x0_low_complex, t, args)\n",
    "loss_obj = custom_loss(args)\n",
    "plot_obj = custom_plot(tf.concat([true_x_low_complex, val_true_x_low_complex], axis=0), tf.concat([x_low_complex, val_x_low_complex], axis=0), \n",
    "                       args.z, tf.concat([t, val_t], axis=0), save_dir_obj.figsave_dir, args)\n",
    "loss_history = nddde.history(args)\n",
    "\n",
    "initial_learning_rate = args.learning_rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=args.niters,\n",
    "    decay_rate=args.decay_rate,\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni3vuuA4JLWc"
   },
   "source": [
    "### Quick test to see how the true coefficients looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhCfEgh9HnJ5"
   },
   "outputs": [],
   "source": [
    "if args.restart == 1: \n",
    "    func.load_weights(tf.train.latest_checkpoint(save_dir_obj.checkpoint_dir))\n",
    "    process_true_z0 = nddde.process_DistDDE_IC(ai_t0, func_aux, t_lowerlim = t[0] - args.nn_d2, t_upperlim = t[0] - args.nn_d1)\n",
    "    pred_zy = ddeinttf(func, process_true_z0, tf.concat([t, val_t], axis=0), fargs=([args.nn_d1, args.nn_d2],), alg_name = args.ode_alg_name, nsteps = args.nsteps)\n",
    "    \n",
    "    plot_obj.plot(pred_zy[:, :, :args.state_dim], epoch = 0)\n",
    "\n",
    "    loss_history.read()\n",
    "    \n",
    "    initial_learning_rate = 0.05\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=args.niters, decay_rate=0.95, staircase=True)\n",
    "    \n",
    "else:\n",
    "    plot_obj.plot(epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RRmGtVWJRWC"
   },
   "source": [
    "### Training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKLUq67EHpoy"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate = lr_schedule)\n",
    "\n",
    "nDistDDE_train_obj = nddde.train_nDistDDE(func = func, adj_func = adj_func, d = [args.nn_d1, args.nn_d2], loss_obj = loss_obj, batch_obj = get_batch,\n",
    "                            optimizer = optimizer, args = args, plot_obj = plot_obj, time_meter = time_meter, checkpoint_dir = save_dir_obj.checkpoint_prefix,\n",
    "                            validation_obj = val_obj, loss_history_obj = loss_history)\n",
    "\n",
    "nDistDDE_train_obj.train(true_x_low_complex, x0_low_complex, t, val_true_x_low_complex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "neuralDistDDE_Bio_Eqn_TestCase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
