{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgv1axkGNvut"
   },
   "outputs": [],
   "source": [
    "basedir = '/home/abhinavgupta0110/NeuralODEs_ROM_Closure'\n",
    "\n",
    "import os\n",
    "\n",
    "is_google_colab = False\n",
    "is_use_GPU = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq_2LQ9UHud0"
   },
   "source": [
    "### Mount the Google drive if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMm0YJf40nu4"
   },
   "outputs": [],
   "source": [
    "if is_use_GPU:\n",
    "    gpu_info = !nvidia-smi\n",
    "    gpu_info = '\\n'.join(gpu_info)\n",
    "    if gpu_info.find('failed') >= 0:\n",
    "        print('No GPU found!')\n",
    "    else:\n",
    "        print(gpu_info)\n",
    "\n",
    "if is_google_colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    %pip install quadpy\n",
    "    \n",
    "os.chdir(os.path.join(basedir, 'neuralDDE_ROM_Closure'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ypp2-6vHzUD"
   },
   "source": [
    "### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-MrPJTQD3Xz4"
   },
   "outputs": [],
   "source": [
    "from src.utilities.DDE_Solver import ddeinttf \n",
    "import src.solvers.neuralDistDDE_with_adjoint as nddde\n",
    "import src.bio_eqn_case.bio_eqn as bio\n",
    "\n",
    "import time\n",
    "import sys\n",
    "from IPython.core.debugger import set_trace\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from shutil import move\n",
    "import pickle\n",
    "\n",
    "tf.keras.backend.set_floatx('float32')\n",
    "import logging\n",
    "tf.get_logger().setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B6M2Jp_VH7k_"
   },
   "source": [
    "## Define some useful classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAACaFzjH8tF"
   },
   "source": [
    "### Class for user-defined arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SuiPlZi330MR"
   },
   "outputs": [],
   "source": [
    "class bio_eq_nDistDDE_args(nddde.nddde_arguments, bio.bio_eqn_args):\n",
    "\n",
    "    def __init__(self, batch_time = 12, batch_time_skip = 2, batch_size = 5, epochs = 500, learning_rate = 0.05, decay_rate = 0.95, test_freq = 1, plot_freq = 2, \n",
    "                 d_max = 1, nn_d1 = 0., nn_d2 = 0.5, adj_data_size = 2,\n",
    "                 model_dir = 'Bio_nDistDDE_testcase/model_dir_test', restart = 0, val_percentage = 0.2,\n",
    "                 T = 2000., nt = 4000, z = -15, k_w = 0.067, alpha = 0.025, V_m = 1.5, I_0 = 158.075, K_u = 1., Psi = 1.46,\n",
    "                    Xi = 0.1, R_m = 1., Lambda = 0.06, gamma = 0.3, Tau = 0.145, Phi = 0.175, Omega = 0.041, T_bio = 30, bio_model_low_complex = 'NPZ', bio_model_high_complex = 'NNPZD', isplot = True): # add more arguments as needed\n",
    "        \n",
    "        if bio_model_low_complex == 'NPZ': state_dim = 3\n",
    "        elif bio_model_low_complex == 'NPZD': state_dim = 4\n",
    "        elif bio_model_low_complex == 'NNPZD': state_dim = 5\n",
    "\n",
    "        nddde.nddde_arguments.__init__(self, data_size = nt, batch_time = batch_time, batch_time_skip = batch_time_skip, batch_size = batch_size, epochs = epochs,\n",
    "                           learning_rate = learning_rate, decay_rate = decay_rate, test_freq = test_freq, plot_freq = plot_freq, d_max = d_max, nn_d1 = nn_d1,\n",
    "                           nn_d2 = nn_d2, state_dim = state_dim, adj_data_size = state_dim, model_dir = model_dir, restart = restart, val_percentage = val_percentage, isplot = isplot)\n",
    "\n",
    "        bio.bio_eqn_args.__init__(self, T = T, nt = nt, z = z, k_w = k_w, alpha = alpha, V_m = V_m, I_0 = I_0, K_u = K_u, Psi = Psi,\n",
    "                    Xi = Xi, R_m = R_m, Lambda = Lambda, gamma = gamma, Tau = Tau, Phi = Phi, Omega = Omega, T_bio = T_bio, bio_model = bio_model_low_complex)\n",
    "        \n",
    "        self.bio_args_for_high_complex = bio.bio_eqn_args(T = T, nt = nt, z = z, k_w = k_w, alpha = alpha, V_m = V_m, I_0 = I_0, K_u = K_u, Psi = Psi,\n",
    "                    Xi = Xi, R_m = R_m, Lambda = Lambda, gamma = gamma, Tau = Tau, Phi = Phi, Omega = Omega, T_bio = T_bio, bio_model = bio_model_high_complex)\n",
    "        \n",
    "        self.bio_model_low_complex = bio_model_low_complex\n",
    "        self.bio_model_high_complex = bio_model_high_complex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bgp85pBOIHjP"
   },
   "source": [
    "### Define the neural net architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uzl-0Opj4CWm"
   },
   "outputs": [],
   "source": [
    "class DDEFuncMain(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DDEFuncMain, self).__init__(**kwargs)\n",
    "        \n",
    "        self.x1 = tf.keras.layers.Dense(7, activation='tanh',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.x2 = tf.keras.layers.Dense(7, activation='tanh',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.out = tf.keras.layers.Dense(args.state_dim, activation='linear',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "\n",
    "    def call(self, z):\n",
    "        for i in range(len(self.layers)):\n",
    "            z = self.layers[i](z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jGruWRo3E4Wf"
   },
   "outputs": [],
   "source": [
    "class DDEFuncAux(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super(DDEFuncAux, self).__init__(**kwargs)\n",
    "        \n",
    "        self.x1 = tf.keras.layers.Dense(5, activation='tanh',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "        \n",
    "        self.x2 = tf.keras.layers.Dense(5, activation='tanh',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "\n",
    "        self.out = tf.keras.layers.Dense(4, activation='linear',\n",
    "                                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.1), use_bias=True)\n",
    "\n",
    "    def call(self, z):\n",
    "        for i in range(len(self.layers)):\n",
    "            z = self.layers[i](z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3JZMekSKE40r"
   },
   "outputs": [],
   "source": [
    "class split_zy:\n",
    "    def __init__(self, zy, args):\n",
    "        self.zy = zy\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self, t):\n",
    "        return self.zy(t)[:, :self.args.state_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2udHo64E6rk"
   },
   "outputs": [],
   "source": [
    "class DistDDEFunc:\n",
    "\n",
    "    def __init__(self, main, aux, rom_model, args):\n",
    "        self.main = main\n",
    "        self.aux = aux\n",
    "        self.rom_model = rom_model\n",
    "        self.args = args\n",
    "\n",
    "    def __call__(self, y, t ,d):\n",
    "        \n",
    "        get_z = split_zy(y, self.args)       \n",
    "\n",
    "        dz_dt = self.main(y(t)) + self.rom_model(get_z, t)\n",
    "        gz_t1 = self.aux(y(t - d[0])[:, :self.args.state_dim])\n",
    "        gz_t2 = self.aux(y(t - d[1])[:, :self.args.state_dim])\n",
    "        dy_dt = gz_t1 - gz_t2\n",
    "        return tf.concat([dz_dt, dy_dt], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jOxl52meIKf7"
   },
   "source": [
    "### Define a custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XlD-fDgm69Nm"
   },
   "outputs": [],
   "source": [
    "class custom_loss:\n",
    "\n",
    "    def __call__(self, true_y, pred_y):\n",
    "        \n",
    "        zero_places = tf.logical_or(tf.less(pred_y, tf.constant([0.])), tf.greater(pred_y, tf.constant([args.T_bio])))\n",
    "        mask_tensor = tf.where(zero_places, 1., 0.)\n",
    "        \n",
    "        loss = tf.reduce_mean(tf.sqrt(tf.reduce_sum(tf.math.squared_difference(pred_y, true_y), axis=-1)), axis=0) \\\n",
    "                + tf.reduce_mean(tf.reduce_sum(mask_tensor, axis=-1), axis=0) \\\n",
    "                 + 0.1 * tf.reduce_mean(tf.math.abs(tf.reduce_sum(pred_y, axis=-1) - args.T_bio), axis=0) \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "COGAzukPIODg"
   },
   "source": [
    "### Define a custom plotting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "348y9-Bf7AzH"
   },
   "outputs": [],
   "source": [
    "class custom_plot:\n",
    "\n",
    "    def __init__(self, true_y, y_no_nn, t, figsave_dir, args):\n",
    "        self.true_y = true_y\n",
    "        self.y_no_nn = y_no_nn\n",
    "        self.t = t\n",
    "        self.figsave_dir = figsave_dir\n",
    "        self.args = args\n",
    "        self.colors = ['b', 'g', 'r', 'k', 'c', 'm']\n",
    "\n",
    "    def plot(self, *pred_y, epoch = 0):\n",
    "        fig = plt.figure(figsize=(6, 4), facecolor='white')\n",
    "        ax_x1 = fig.add_subplot(111)\n",
    "\n",
    "        ax_x1.cla()\n",
    "        ax_x1.set_title('Bio Model Comparison')\n",
    "        ax_x1.set_xlabel('t')\n",
    "        ax_x1.set_ylabel('Bio Variable')\n",
    "        ax_x1.plot(self.t.numpy(), self.true_y.numpy()[:, 0, 0], '-r', label = 'N (High Complex)')\n",
    "        ax_x1.plot(self.t.numpy(), self.y_no_nn.numpy()[:, 0, 0], '--r', label = 'N (NPZ)')\n",
    "        ax_x1.plot(self.t.numpy(), self.true_y.numpy()[:, 0, 1], '-g', label = 'P (High Complex)')\n",
    "        ax_x1.plot(self.t.numpy(), self.y_no_nn.numpy()[:, 0, 1], '--g', label = 'P (NPZ)')\n",
    "        ax_x1.plot(self.t.numpy(), self.true_y.numpy()[:, 0, 2], '-b', label = 'Z (High Complex)')\n",
    "        ax_x1.plot(self.t.numpy(), self.y_no_nn.numpy()[:, 0, 2], '--b', label = 'Z (NPZ)')\n",
    "\n",
    "        if epoch != 0 or self.args.restart == 1 :\n",
    "            ax_x1.plot(self.t.numpy(), pred_y[0].numpy()[:, 0, 0], '-.r', label = 'N (Learned)')\n",
    "            ax_x1.plot(self.t.numpy(), pred_y[0].numpy()[:, 0, 1], '-.g', label = 'P (Learned)')\n",
    "            ax_x1.plot(self.t.numpy(), pred_y[0].numpy()[:, 0, 2], '-.b', label = 'Z (Learned)')\n",
    "\n",
    "        ax_x1.set_xlim(self.t[0], self.t[-1])\n",
    "        ax_x1.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
    "\n",
    "        plt.show() \n",
    "\n",
    "        if epoch != 0: \n",
    "            fig.savefig(os.path.join(self.figsave_dir, 'img'+str(epoch)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPytNA8cIf-S"
   },
   "source": [
    "### Initial Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XokaBF_C5HZh"
   },
   "outputs": [],
   "source": [
    "class initial_cond:\n",
    "\n",
    "    def __init__(self, app):\n",
    "        self.app = app\n",
    "\n",
    "    def __call__(self, t):\n",
    "\n",
    "        if self.app.bio_model == 'NPZ':\n",
    "            x0 = [self.app.T_bio - 0.5*2, 0.5, 0.5]\n",
    "        elif self.app.bio_model == 'NPZD':\n",
    "            x0 = [self.app.T_bio - 0.5*2, 0.5, 0.5, 0.]\n",
    "        elif self.app.bio_model == 'NNPZD':\n",
    "            x0 = [self.app.T_bio/2., self.app.T_bio/2. - 2*0.5, 0.5, 0.5, 0.]\n",
    "        return tf.convert_to_tensor([x0], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55JqC28YIS6c"
   },
   "source": [
    "### Initialize model related parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AYlTE72b4PE2"
   },
   "outputs": [],
   "source": [
    "args = bio_eq_nDistDDE_args(batch_time = 6, batch_time_skip = 2, batch_size = 8, epochs = 200, learning_rate = 0.05, decay_rate = 0.97, test_freq = 1, plot_freq = 1,\n",
    "                    d_max = 3., nn_d1 = 0., nn_d2 = 2.0, model_dir = 'Bio_nDistDDE_testcase/model_dir_case', restart = 0, val_percentage = 1.,\n",
    "                    T = 20., nt = 400, z = -15, k_w = 0.067, alpha = 0.025, V_m = 1.5, I_0 = 158.075, K_u = 1., Psi = 1.46,\n",
    "                    Xi = 0.1, R_m = 1.5, Lambda = 0.06, gamma = 0.3, Tau = 0.145, Phi = 0.175, Omega = 0.041, T_bio = 30., bio_model_low_complex = 'NPZ', bio_model_high_complex = 'NNPZD')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3D0icD8IV9O"
   },
   "source": [
    "### Make a copy of the current script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "204TIzQKHNzQ"
   },
   "outputs": [],
   "source": [
    "os.chdir(basedir)\n",
    "\n",
    "if not os.path.exists(args.model_dir):\n",
    "    os.makedirs(args.model_dir)\n",
    "\n",
    "checkpoint_dir_main = os.path.join(args.model_dir, \"ckpt_main\")\n",
    "checkpoint_dir_aux = os.path.join(args.model_dir, \"ckpt_aux\")\n",
    "checkpoint_prefix_main = os.path.join(checkpoint_dir_main, \"cp-{epoch:04d}.ckpt\")\n",
    "checkpoint_prefix_aux = os.path.join(checkpoint_dir_aux, \"cp-{epoch:04d}.ckpt\")\n",
    "if not os.path.exists(checkpoint_dir_main):\n",
    "  os.makedirs(checkpoint_dir_main)\n",
    "if not os.path.exists(checkpoint_dir_aux):\n",
    "  os.makedirs(checkpoint_dir_aux)\n",
    "\n",
    "figsave_dir = os.path.join(args.model_dir, \"img\")\n",
    "if not os.path.exists(figsave_dir):\n",
    "    os.makedirs(figsave_dir)\n",
    "\n",
    "!jupyter nbconvert --to python neuralDDE_ROM_Closure/testcases/Bio_Eqn/neuralDistDDE_Bio_Eqn_TestCase.ipynb\n",
    "move(\"neuralDDE_ROM_Closure/testcases/Bio_Eqn/neuralDistDDE_Bio_Eqn_TestCase.py\", os.path.join(args.model_dir, \"orig_run_file.py\"))\n",
    "\n",
    "pickle.dump( args, open( os.path.join(args.model_dir, \"args.p\"), \"wb\" ) )\n",
    "with open(os.path.join(args.model_dir, 'args.pkl'), 'wb') as output:\n",
    "    pickle.dump(args, output, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CeBwqst9IqRq"
   },
   "source": [
    "### Solve for the high complexity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qzk4Frf04QHp"
   },
   "outputs": [],
   "source": [
    "t = tf.linspace(0., args.T, args.nt) # Time array\n",
    "\n",
    "x0_high_complex = initial_cond(args.bio_args_for_high_complex) # Initial conditions\n",
    "\n",
    "x_high_complex = ddeinttf(bio.bio_eqn(args.bio_args_for_high_complex), x0_high_complex, t)\n",
    "\n",
    "# Compute FOM for the validation time\n",
    "dt = t[1] - t[0]\n",
    "val_t_len =  args.val_percentage * (t[-1] - t[0])\n",
    "n_val = np.ceil(np.abs(val_t_len/dt.numpy())).astype(int)\n",
    "val_t = tf.linspace(t[-1], t[-1] + val_t_len, n_val)\n",
    "\n",
    "val_x_high_complex = ddeinttf(bio.bio_eqn(args.bio_args_for_high_complex), nddde.create_interpolator(x_high_complex, t), val_t)\n",
    "\n",
    "print('Higher complexity model done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zOz2tIzWIuQB"
   },
   "source": [
    "### Transform states of high complexity model to low complexity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Vk1e9Pq5EaD"
   },
   "outputs": [],
   "source": [
    "# Create modes for the training and validation period combined\n",
    "true_x_low_complex = bio.convert_high_complex_to_low_complex_states(x_high_complex, args)\n",
    "\n",
    "x0_low_complex = initial_cond(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnNELD1OmEJV"
   },
   "source": [
    "Solve the low complexity model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L-L5e-JGmDdP"
   },
   "outputs": [],
   "source": [
    "x_low_complex = ddeinttf(bio.bio_eqn(args), x0_low_complex, t)\n",
    "\n",
    "val_x_low_complex = ddeinttf(bio.bio_eqn(args), nddde.create_interpolator(x_low_complex, t), val_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aInSylAY2mlN"
   },
   "source": [
    "#### Create validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PBAXVKkl2pM5"
   },
   "outputs": [],
   "source": [
    "val_obj = nddde.create_validation_set_nddde(x0_low_complex, t, args)\n",
    "\n",
    "val_true_x_low_complex = bio.convert_high_complex_to_low_complex_states(val_x_high_complex, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o9mHAYKBI1vM"
   },
   "source": [
    "## Main part starts here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pscaRbpsJE25"
   },
   "source": [
    "### Make objects and define learning-rate schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cnb1m74W8a3l"
   },
   "outputs": [],
   "source": [
    "time_meter = nddde.RunningAverageMeter(0.97)\n",
    "\n",
    "func_main = DDEFuncMain()\n",
    "func_aux = DDEFuncAux()\n",
    "func = DistDDEFunc(func_main, func_aux, bio.bio_eqn(app = args), args)\n",
    "adj_func = nddde.nddde_adj_eqn(func, args)\n",
    "get_batch = nddde.create_batch(true_x_low_complex, x0_low_complex, t, args)\n",
    "loss_obj = custom_loss()\n",
    "plot_obj = custom_plot(tf.concat([true_x_low_complex, val_true_x_low_complex], axis=0), tf.concat([x_low_complex, val_x_low_complex], axis=0), \n",
    "                       tf.concat([t, val_t], axis=0), figsave_dir, args)\n",
    "loss_history = nddde.history(args)\n",
    "\n",
    "initial_learning_rate = args.learning_rate\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate,\n",
    "    decay_steps=args.niters,\n",
    "    decay_rate=args.decay_rate,\n",
    "    staircase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ni3vuuA4JLWc"
   },
   "source": [
    "### Quick test to see how the true coefficients looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KhCfEgh9HnJ5"
   },
   "outputs": [],
   "source": [
    "if args.restart == 1: \n",
    "    func_main.load_weights(tf.train.latest_checkpoint(checkpoint_dir_main))\n",
    "    func_aux.load_weights(tf.train.latest_checkpoint(checkpoint_dir_aux))\n",
    "    process_true_z0 = nddde.process_DistDDE_IC(ai_t0, func_aux, t_lowerlim = t[0] - args.nn_d2, t_upperlim = t[0] - args.nn_d1)\n",
    "    pred_zy = ddeinttf(func, process_true_z0, tf.concat([t, val_t], axis=0), fargs=([args.nn_d1, args.nn_d2],))\n",
    "    \n",
    "    plot_obj.plot(pred_zy[:, :, :args.state_dim], epoch = 0)\n",
    "\n",
    "    loss_history.read()\n",
    "    \n",
    "    initial_learning_rate = 0.05\n",
    "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "        initial_learning_rate, decay_steps=args.niters, decay_rate=0.95, staircase=True)\n",
    "    \n",
    "else:\n",
    "    plot_obj.plot(epoch = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3RRmGtVWJRWC"
   },
   "source": [
    "### Training starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CKLUq67EHpoy"
   },
   "outputs": [],
   "source": [
    "optimizer_main = tf.keras.optimizers.RMSprop(learning_rate = lr_schedule)\n",
    "optimizer_aux = tf.keras.optimizers.RMSprop(learning_rate = lr_schedule)\n",
    "\n",
    "nDistDDE_train_obj = nddde.train_nDistDDE(func = func, adj_func = adj_func, d = [args.nn_d1, args.nn_d2], loss_obj = loss_obj, batch_obj = get_batch,\n",
    "                            checkpoint_dir_aux = checkpoint_prefix_aux, optimizer_main = optimizer_main, optimizer_aux = optimizer_aux, args = args, plot_obj = plot_obj, time_meter = time_meter, checkpoint_dir_main = checkpoint_prefix_main,\n",
    "                            validation_obj = val_obj, loss_history_obj = loss_history)\n",
    "\n",
    "nDistDDE_train_obj.train(true_x_low_complex, x0_low_complex, t, val_true_x_low_complex)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "neuralDistDDE_Bio_Eqn_TestCase.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
